{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5c732907",
   "metadata": {},
   "source": [
    "<center>\n",
    "<div style=\"text-align: Center\">Documents by Context Category</div>\n",
    "<div style=\"text-align: Center\">Learns Relationships</div>\n",
    "<div style=\"text-align: Center\">Pawel Sobieralski, 2022 </div>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04bf9aa9",
   "metadata": {},
   "source": [
    "# Solution Design - Linear Relationships\n",
    "\n",
    "Determine to which context category document belongs\n",
    "\n",
    "## Description:\n",
    "This solution is based on finding document vector representation doc2vec meaning and uses gensim implementation. Then it uses its remarkable linear relationships to compare each context with new document. Vector space have similar meanings based on context, and vectors distant to each other have differing meanings.\n",
    "\n",
    "Is vector(“**new document**”) more similiar to:\n",
    "\n",
    "vector(\"**laundering activity**\") - vector('**allegations','accusations','charges**') + vector('**conviction','sentencing**')  \n",
    "\n",
    "or is it similiar to:\n",
    "\n",
    "vector(\"**laundering activity**\") - vector('**conviction','sentencing**') + vector('**allegations','accusations','charges**')\n",
    "\n",
    "\n",
    "## Example usage:\n",
    " \n",
    "<strong>Preprocess</strong>  \n",
    "train_doc = se_process_document(train_corpus)  \n",
    "test_doc = se_process_document(test_document)\n",
    "\n",
    "<strong>Build vector space</strong>  \n",
    "vocab_dict = se_build_vocabulary(train_doc)\n",
    "\n",
    "<strong>Build context vectors</strong>  \n",
    "train_vector = se_build_context(train_doc,vocab_dict)\n",
    "test_vector = se_build_context(test_doc,vocab_dict)\n",
    "\n",
    "<strong>Compare documents in given category</strong>  \n",
    "se_compare_by_context(train_vector, test_vector, context1)\n",
    "\n",
    "## Files list\n",
    "\n",
    "Compare Documents by Context Category - Jupiter Notebook with solution prototype  \n",
    "utils.py - Utilities  \n",
    "DocByContextCategory.py - The same solution as a Python class  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "50b6eb6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"../Python\")\n",
    "\n",
    "from utils import se_cosine_similarity\n",
    "\n",
    "from gensim.test.utils import common_texts\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "from gensim import corpora"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4dc5fd5",
   "metadata": {},
   "source": [
    "# Sample Corpus\n",
    "\n",
    "These documents are assumed to be all money laundering documents. While the sentences may not necessarily make sense to humans - they have properties required for this project - corpus with multiple context. \n",
    "\n",
    "First 5 sentences [allegations,accusations,charges]\n",
    "\n",
    "Last 4 sentences [conviction,sentencing]\n",
    "\n",
    "Also - unseen before document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28805b96",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = [\n",
    "    \"Laundering Human machine interface for lab abc allegations applications\",\n",
    "    \"Laundering A survey of user opinion of allegations accusations charges time\",\n",
    "    \"Laundering The EPS user interface management accusations\",\n",
    "    \"Laundering Accusations and human accusations engineering testing of EPS\",\n",
    "    \"Laundering Relation of user perceived charges time to error measurement\",\n",
    "    \"Laundering The generation of random binary unordered conviction\",\n",
    "    \"Laundering The intersection sentencing of paths in conviction\",\n",
    "    \"Laundering Sentencing minors IV Widths of conviction and well quasi ordering\",\n",
    "    \"Laundering Sentencing minors A survey\",\n",
    "]\n",
    "\n",
    "context1 = ['allegations','accusations','charges']\n",
    "context2 = ['conviction','sentencing']\n",
    "\n",
    "#Unseen before document\n",
    "#It belongs to context 1 but it does not contain any keyword from context 1\n",
    "test_document = [\"Machine versus human movies\"]\n",
    "\n",
    "text_tokens = [[text for text in mydoc.split()] for mydoc in train_corpus]\n",
    "text_dict = corpora.Dictionary(text_tokens)\n",
    "dictionary_tokens = text_dict.token2id.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec4b6cb",
   "metadata": {},
   "source": [
    "# Build Model\n",
    "\n",
    "Estimate model parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "22a97da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_build_model(train_corpus, vector_size, window, min_count=1, workers=4):\n",
    "    \n",
    "    documents = [TaggedDocument(doc, [i]) for i, doc in enumerate(train_corpus)]\n",
    "    model = Doc2Vec(documents, vector_size=vector_size, window=window, min_count=1, workers=4)\n",
    "\n",
    "    return model\n",
    "\n",
    "model = se_build_model(train_corpus,len(dictionary_tokens), 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fe1cc00",
   "metadata": {},
   "source": [
    "# Infer Vector\n",
    "Infer Vector for a New Document, Context 1 and Context 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3fe4be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def se_infer_vector(model, sentence):\n",
    "    \n",
    "    return model.infer_vector(sentence)\n",
    "\n",
    "corpus_vector = se_infer_vector(model, dictionary_tokens) #corpus\n",
    "new_document_vector = se_infer_vector(model, test_document) #Test document\n",
    "\n",
    "context1_vector = se_infer_vector(model, context1)\n",
    "context2_vector = se_infer_vector(model, context2)\n",
    "laundering_vector = se_infer_vector(model, ['laundering'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d321bb",
   "metadata": {},
   "source": [
    "# Similiarity Between Context Category and Unseen Document\n",
    "Compare new document vector with each context vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "726887fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import se_cosine_similarity\n",
    "\n",
    "def get_context_category(new_doc_vector, context1_vector, context2_vector):\n",
    "    \n",
    "    context1_similiarity = se_cosine_similarity(new_doc_vector,context1_vector)\n",
    "    context2_similiarity = se_cosine_similarity(new_doc_vector,context2_vector)\n",
    "    \n",
    "    print(\"New document similiarity with context 1 is \" + str(context1_similiarity))\n",
    "    print(\"New document similiarity with context 2 is \" + str(context2_similiarity))\n",
    "    \n",
    "    if context1_similiarity > context2_similiarity:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70eb8bc",
   "metadata": {},
   "source": [
    "# Context Category from Linear Relationship\n",
    "\n",
    "Is vector(“**new document**”) more similiar to:\n",
    "\n",
    "vector(\"**laundering activity**\") - vector('**allegations','accusations','charges**') + vector('**conviction','sentencing**')  \n",
    "\n",
    "or is it similiar to:\n",
    "\n",
    "vector(\"**laundering activity**\") - vector('**conviction','sentencing**') + vector('**allegations','accusations','charges**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "73b38f25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New document similiarity with context 1 is 0.04724569\n",
      "New document similiarity with context 2 is 0.016226169\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "laundering_context1 = laundering_vector - context2_vector + context1_vector\n",
    "laundering_context2 = laundering_vector - context1_vector + context2_vector\n",
    "\n",
    "get_context_category(new_document_vector, laundering_context1, laundering_context2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
